# -*- coding: utf-8 -*-
"""CSE6250.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOKLfbKC_IGsXkQGmjnSai57F1N5bRtw
"""

from google.colab import drive
drive.mount('/content/drive')
# load tqdm
!pip install --force https://github.com/chengs/tqdm/archive/colab.zip

from google.colab import files
uploaded = files.upload()

#### Data Prep ####a
import pandas as pd
import numpy as np
import os
import io

admin_file = io.BytesIO(uploaded['ADMISSIONS.csv'])
diag_file = io.BytesIO(uploaded['DIAGNOSES_ICD.csv'])
procedure_file = io.BytesIO(uploaded['PROCEDURES_ICD.csv'])
prescript_file = io.BytesIO(uploaded['PRESCRIPTIONS.csv'])
drug_file = io.BytesIO(uploaded['DRGCODES.csv'])

datasets_path = '.\\mimic3_demo_data\\'

def convert_to_high_level_icd9(icd9_code):
    k = icd9_code[:3]
    if '001' <= k <= '139':
        return 0
    elif '140' <= k <= '239':
        return 1
    elif '240' <= k <= '279':
        return 2
    elif '280' <= k <= '289':
        return 3
    elif '290' <= k <= '319':
        return 4
    elif '320' <= k <= '389':
        return 5
    elif '390' <= k <= '459':
        return 6
    elif '460' <= k <= '519':
        return 7
    elif '520' <= k <= '579':
        return 8
    elif '580' <= k <= '629':
        return 9
    elif '630' <= k <= '679':
        return 10
    elif '680' <= k <= '709':
        return 11
    elif '710' <= k <= '739':
        return 12
    elif '740' <= k <= '759':
        return 13
    elif '760' <= k <= '779':
        return 14
    elif '780' <= k <= '799':
        return 15
    elif '800' <= k <= '999':
        return 16
    elif 'E00' <= k <= 'E99':
        return 17
    elif 'V01' <= k <= 'V90':
        return 18


def data_prep(admin_file, diag_file, procedure_file, prescript_file, drug_file):

    # df_adm = pd.read_csv(os.getcwd() + datasets_path + admin_file, dtype=str)
    # df_diags = pd.read_csv(os.getcwd() + datasets_path + diag_file, dtype=str)
    # df_procedures = pd.read_csv(os.getcwd() + datasets_path + procedure_file, dtype=str)
    # df_prescripts = pd.read_csv(os.getcwd() + datasets_path + prescript_file, dtype=str)
    # df_drugs = pd.read_csv(os.getcwd() + datasets_path + drug_file, dtype=str)

    df_adm = pd.read_csv(admin_file, dtype=str)
    df_diags = pd.read_csv(diag_file, dtype=str)
    df_procedures = pd.read_csv(procedure_file, dtype=str)
    df_prescripts = pd.read_csv(prescript_file, dtype=str)
    df_drugs = pd.read_csv(drug_file, dtype=str)

    df_adm['admittime'] = pd.to_datetime(df_adm['admittime'])
    df_adm['dischtime'] = pd.to_datetime(df_adm['dischtime'])
    df_adm['num_days'] = (df_adm['dischtime'] - df_adm['admittime']).dt.days + 1
    df_adm = df_adm.rename(columns={'hospital_expire_flag':'death_flag'})

    #df_diags = df_diags.rename(columns={'icd9_code':'icd9_diag'})
    #df_diags['icd9_parent'] = df_diags['icd9_code'].apply(lambda x: x[:4] if x[0] == 'E' else x[:3])
    df_diags['icd9_category'] = df_diags['icd9_code'].apply(convert_to_high_level_icd9)
    df_diags['icd9_diag'] = df_diags[['seq_num', 'icd9_category']].apply(tuple, axis=1)
    df_procedures = df_procedures.rename(columns={'icd9_code':'icd9_proced'})

    icd9_diag_categories = list(range(19))

    df_diags2 = df_diags.loc[:,['subject_id', 'hadm_id', 'icd9_diag']].dropna()
    df_adm2 = df_adm.loc[:,['hadm_id', 'admittime', 'num_days', 'death_flag']]
    df = df_diags2.merge(df_adm2, how='left', on='hadm_id')

    df_procedures2 = df_procedures.loc[:,['hadm_id', 'icd9_proced']].dropna()
    df2 = df.merge(df_procedures2, how='left', on='hadm_id')

    df_prescripts2 = df_prescripts.loc[:,['hadm_id', 'ndc']].dropna()
    df_prescripts2 = df_prescripts2[df_prescripts2['ndc']!='0']
    df3 = df2.merge(df_prescripts2, how='left', on='hadm_id')

    df_drugs2 = df_drugs.loc[:,['hadm_id', 'drg_code']].dropna()
    df4 = df3.merge(df_drugs2, how='left', on='hadm_id')

    df5 = df4.groupby(['subject_id', 'hadm_id']).agg(set)

    def sort_list(row):
        row2 = sorted(row, key=lambda x: int(x[0]))
        return [x[1] for x in row2]

    df5['icd9_diag'] = df5['icd9_diag'].apply(list)
    df5['icd9_diag'] = df5['icd9_diag'].apply(sort_list)
    df5['icd9_diag'] = df5['icd9_diag'].apply(lambda x: list(dict.fromkeys(x)))
    df5['icd9_proced'] = df5['icd9_proced'].apply(list)
    df5['ndc'] = df5['ndc'].apply(list)
    df5['drg_code'] = df5['drg_code'].apply(list)
    #df5['admittime'] = df5['admittime'].apply(lambda x: list(x)[0].strftime("%Y-%m-%d"))
    df5['admittime'] = df5['admittime'].apply(lambda x: list(x)[0])
    df5['num_days'] = df5['num_days'].apply(lambda x: list(x)[0]).astype(str)

    df6 = df5.reset_index()
    df6['death_flag'] = df6['death_flag'].apply(lambda x: list(x)[0])

    data = []
    patient_ids = df6['subject_id'].unique()
    for p_id in patient_ids:
        patient = {}
        df_p_id = df6[df6['subject_id']==p_id].sort_values('admittime')
        adm_ids = df_p_id.loc[:,'hadm_id']
        visits = []
        for adm_id in adm_ids:
            df_visit = df6[(df6['subject_id']==p_id) & (df6['hadm_id']==adm_id)]
            visit = {}
            visit['admittime'] = df_visit['admittime'].values[0]
            visit['num_days'] = df_visit['num_days'].values[0]
            visit['death_flag'] = df_visit['death_flag'].values[0]
            visit['icd9_diags'] = df_visit['icd9_diag'].values[0]
            visit['icd9_procedures'] = df_visit['icd9_proced'].values[0]
            visit['prescriptions'] = df_visit['ndc'].values[0]
            visit['drugs'] = df_visit['drg_code'].values[0]
            visits.append(visit)
        patient[p_id] = visits
        data.append(patient)

    return (data, icd9_diag_categories)

#%%
def get_last_code(data):
    last_codes = []
    for patient in data:
        for k in patient.keys(): 
            last = patient[k][-1]['icd9_diags'].pop()
            last_codes.append((last))
    return last_codes

def dataset_encoding(data, icd9_categories, max_visits):
    max_visits = 5
    dataset = np.zeros((len(data), len(icd9_categories), max_visits))
    for i, patient in enumerate(data):
        for p_id in patient.keys():
            for j, visit in enumerate(patient[p_id]):
                if j > max_visits-1:
                    continue
                else:
                    check_array = np.arange(len(icd9_categories))
                    visit_array = np.array(visit['icd9_diags'])
                    dataset[i,:,j] = np.in1d(check_array, visit_array).astype(int)
    return dataset

import torch
from torch import nn
import numpy as np
import torch.nn.functional as F
import math


class AttnPooling(nn.Module):

    def __init__(self, emb_dim):
       super().__init__()
       self.dense1 = nn.Linear(emb_dim, emb_dim)
       self.dense2 = nn.Linear(emb_dim, emb_dim)
       self.relu = nn.ReLU()
       self.softmax = nn.Softmax(1)
    
    def forward(self, x, mask):
       bsz, ch, emb = x.size()
       residual = x

       # Dense 1
       x = x.reshape(bsz * ch, emb)
       x = self.relu(self.dense1(x))
       x = x.reshape(bsz, ch, emb)

       # Dense 2
       x = x.reshape(bsz * ch, emb)
       x = self.dense2(x)
       x = x.reshape(bsz,  ch, emb)

       x *= mask
       x = self.softmax(x)
       x = torch.sum(x * residual, 1)
       return x


class MaskedEncoderBlock(nn.Module):
    def __init__(self, n_emb, n_heads, dropout=.01, mask_type=None):
       super().__init__()
       self.n_head = n_heads
       self.key = nn.Linear(n_emb, n_emb)
       self.query = nn.Linear(n_emb, n_emb)
       self.value = nn.Linear(n_emb, n_emb)

       self.dropout = nn.Dropout(dropout)
       self.layer_norm = nn.LayerNorm(n_emb, eps=1e-6)

       self.proj = nn.Linear(n_emb, n_emb)
       self.fc = nn.Linear(n_emb, n_emb)
       self.mask_type = mask_type

    def forward(self, x, mask):

        B, T, C = x.size()
        residual = x

        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)
        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)

        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))

        if self.mask_type == "diag":
            attn_mask = torch.ones([T, T]).triu().tril() * float("-inf")
            attn_mask = attn_mask.reshape(1, 1, T, T,)
            attn_mask[torch.isnan(attn_mask)] = 0
        elif self.mask_type == "forward":
            attn_mask = torch.ones([T, T]).tril(diagonal=-1) * float("-inf")
            attn_mask = attn_mask.reshape(1, 1, T, T, )
            attn_mask[torch.isnan(attn_mask)] = 0
        else:
            attn_mask = torch.ones([T, T]).triu(diagonal=1) * float("-inf")
            attn_mask = attn_mask.reshape(1, 1, T, T, )
            attn_mask[torch.isnan(attn_mask)] = 0
        att += attn_mask

        att = F.softmax(att, dim=-1)
        att = self.dropout(att)
        y = att @ v   # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)
        y = y.transpose(1, 2).contiguous().view(B, T, C)
        y = self.proj(y)
        y *= mask

        x = self.layer_norm(y) + residual
        residual = x
        x = self.fc(x)
        x = self.layer_norm(x) + residual
        return x


class BiteNet(nn.Module):

    def __init__(self, embedding_dim, output_dim, n_heads, blocks, n_visits, n_codes):
      super().__init__()

      # embedding layers
      self.emb = nn.Embedding(n_visits * n_codes, embedding_dim)
      self.int_emb = nn.Embedding(n_visits, embedding_dim)

      self.masc_enc_diag = MaskedEncoderBlock(embedding_dim, n_heads, mask_type="diag")
      self.masc_enc_forward = MaskedEncoderBlock(embedding_dim, n_heads, mask_type="forward")
      self.masc_enc_backward = MaskedEncoderBlock(embedding_dim, n_heads, mask_type="backward")

      # weird attn layers
      self.attn_pool1 = AttnPooling(embedding_dim)
      self.attn_pool2 = AttnPooling(embedding_dim)
      self.attn_pool3 = AttnPooling(embedding_dim)

      # fully Connected Layers
      self.fc1 = nn.Linear(embedding_dim * 2, embedding_dim)
      self.logits = nn.Linear(embedding_dim, output_dim)
      self.relu = nn.ReLU()
      self.sig = nn.Sigmoid()

    def forward(self, x, intervals):
      bsz, visits, codes, = x.size()

      base_mask = torch.ne(x, 0).float()
      base_mask_v = torch.sum(base_mask, -1)

      input_mask = base_mask
      input_mask = input_mask.reshape(bsz * visits, codes, 1)

      input_mask_v = base_mask_v
      input_mask_v = input_mask_v.reshape(bsz, visits, 1)

      emb = self.emb(x).reshape(bsz * visits, codes, -1)
      int_emb = self.int_emb(intervals)

      x = self.masc_enc_diag(emb, input_mask)
      x = self.attn_pool1(x, input_mask)
      x = x.reshape(bsz, visits, -1)
      x = x + int_emb

      y = self.masc_enc_forward(x, input_mask_v)
      y = self.attn_pool2(y, input_mask_v)

      z = self.masc_enc_backward(x, input_mask_v)
      z = self.attn_pool3(z, input_mask_v)

      x = torch.cat([y, z], dim=-1)
      x = self.relu(self.fc1(x))
      x = self.sig(self.logits(x))
      return x

def target_to_onehot(target, dataset):
  target_onehot = np.zeros((dataset.shape[0], dataset.shape[1]))
  for i, t in enumerate(target):
      check_array = np.arange(dataset.shape[1])
      target_array = np.array([t])
      target_onehot[i,:] = np.in1d(check_array, target_array).astype(int)
  return target_onehot

class MedDataset(Dataset):
     def __init__(self, max_visits, admin_file, diag_file, procedure_file, prescript_file, drug_file):
        data, icd9_diag_categories = data_prep(admin_file, diag_file, procedure_file, prescript_file, drug_file)
        self.targets = get_last_code(data)
        dataset = dataset_encoding(data, icd9_diag_categories, max_visits)
        self.target_onehot = target_to_onehot(self.targets, dataset)
        intervals = np.moveaxis(dataset.copy(), 1, -1)[:, :, 0]
        target_torch = torch.from_numpy(self.target_onehot)
        dataset_torch = torch.from_numpy(dataset)
        intervals_torch = torch.from_numpy(intervals)
        self.data_tensor = TensorDataset(dataset_torch.transpose(1, -1), intervals_torch, target_torch)

     def __len__(self):
        return len(self.targets)

     def get_data(self):
        return self.data_tensor

from torch.optim import Adam
from tqdm import tqdm
from torch.utils.data.sampler import SubsetRandomSampler
num_epochs = 10
lr = .001
embedding_dim = 128
n_heads = 4
output_dim = 19
n_codes = 19
n_visits = 5
blocks = 1

max_visits = 5
dataset = MedDataset(max_visits, admin_file, diag_file, procedure_file, prescript_file, drug_file)
med_dataset = dataset.get_data()
dataset_size = len(med_dataset)
indices = list(range(dataset_size))
split = int(np.floor(.25 * dataset_size))
np.random.seed(42)
np.random.shuffle(indices)
train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
val_sampler = SubsetRandomSampler(val_indices)

train_dataloader = DataLoader(med_dataset, batch_size=10,  sampler=train_sampler)
val_dataloader = DataLoader(med_dataset, batch_size=10, sampler=val_sampler)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

model = BiteNet(embedding_dim, output_dim, n_heads, blocks, n_visits, n_codes).to(device)
opt = Adam(model.parameters(), lr=lr)
criterion = nn.BCELoss()

best_model = 1000

for epoch in range(num_epochs):
  print("### Epoch: " + str(epoch) + " ###")
  # Perform Trainstep
  for i, (input, intervals, target) in enumerate(tqdm(train_dataloader)):
     model.train()
     input, intervals, target = input.to(device).long(), intervals.to(device).long(), target.to(device).float()
     opt.zero_grad()
     output = model(input, intervals)
     loss = criterion(output, target)
     print("\nTrain Loss: ", loss.detach().cpu())
     loss.backward()
     opt.step()

  for i, (input, intervals, target) in enumerate(tqdm(val_dataloader)):
     model.eval()
     input, intervals, target = input.to(device).long(), intervals.to(device).long(), target.to(device).float()
     output = model(input, intervals)
     val_loss = criterion(output, target)
     print("\nVal Loss: ", loss.detach().cpu())
     if val_loss.detach().cpu() < best_model:
         torch.save(model.state_dict(), "best_model_e_" + str(epoch) + "_loss_" + str(val_loss.detach().cpu()) + ".ckpt")
         best_model = val_loss.detach().cpu()

